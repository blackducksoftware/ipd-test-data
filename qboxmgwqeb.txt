Here is a sample code in Python that uses the BeautifulSoup library to scrape data from a website and store it in a CSV file:

```python
import requests
from bs4 import BeautifulSoup
import csv

url = 'https://example.com' # Replace this with the URL of the website you want to scrape

response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

articles = []
for article in soup.find_all('article'):
    title = article.find('h2').text
    url = article.find('a')['href']
    articles.append({'title': title, 'url': url})

# Write data to CSV file
csv_file = 'articles.csv'
with open(csv_file, mode='w', newline='') as file:
    writer = csv.DictWriter(file, fieldnames=['title', 'url'])
    writer.writeheader()
    for article in articles:
        writer.writerow(article)

print(f'Data extracted and saved to {csv_file}')
```

This code will scrape the titles and URLs of articles from the specified website and save them in a CSV file named 'articles.csv'. Additionally, it includes basic error handling for missing elements on the page by using try-except blocks or conditional statements to handle potential errors.